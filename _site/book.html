<doc>
  <head>
    <title>The cromulent testing handbook</title>
    <date>INSERT DATE</date>
    <author>INSERT AUTHORS</author>
  </head>
<body>
  <!--
  [undefined front matter]

  [blank]                 [a fear and loathing of testing]

  [section header]        [section toc]
  [article]               [article or blank]
  [article]               [article or blank]
  [article]               [article or blank]
  [article]               [article or blank]

  [a little bit about this book]

  [undefined closing matter]
  -->

  <intro>
  
    
      <p><strong>Ash</strong>: <em>We were somewhere around the waterfall, on the edge of the software lifecycle, when the tests began to take hold. I remember saying something like:</em></p>
<br />
<p>I feel a bit lightheaded. Maybe you should drive.</p>
<br />
<p><em>Suddenly, there was a terrible roar all around us, and the software was full of what looked like huge bugs, all swooping and screeching and diving around the computer, and a voice was screaming:</em></p>
<br />
<p>Holy Jesus. What are these goddamn bugs?</p>
<br />
<p><strong>Dr. Gonzo</strong>: Did you say something?</p>
<br />
<p><strong>Ash</strong>: Hm? Never mind. It&#8217;s your turn to test.</p>
<br />
<p><strong>Ash</strong>: <em>No point in mentioning these bugs, I thought. Poor bastard will see them soon enough.</em></p>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</intro>
  <section>
  <title>Concepts</title>
  <articles>
    
      
    
      
        <article>
          <title>challenging assumptions</title>
          <p>Many bugs can be prevented by challenging assumptions. Challenging the assumptions every one holds as well as paying attention to the seemingly small ones, will yield great results.</p>

<p>Small things can be the most dangerous as they tend to go unnoticed, then gang up on you. It’s more common for projects to get overwhelmed by a build up of small things. The devil’s in the detail.</p>

<p>To find assumptions, listen to the way people speak. Assumptions can found in sentences that contain:</p>

<ul>
<li>must, always, mandatory, required</li>

<li>impossible, inconceivable, never</li>

<li>should, ought</li>

<li>doesn’t make sense</li>
</ul>
<br />
<p><em>Doesn’t make sense is a favourite.</em> This planet is filled with humans who do many things that make more money than sense.</p>

<h3 id='an_example'>An Example!</h3>

<p>Consider the following story:</p>

<p><em>As a customer</em> <br /> <em>I want to know the average activity</em> <br /> <em>So that I can compare this month’s activity against the average</em> <br /></p>

<p>Sounds simple&#8230; but if you look a little deeper:</p>

<ul>
<li>What do we mean by ‘know’?</li>

<li>What do we mean by average? <a href='http://en.wikipedia.org/wiki/Geometric_mean'>Geometric</a>, <a href='http://en.wikipedia.org/wiki/Harmonic_mean'>harmonic</a> or <a href='http://en.wikipedia.org/wiki/Arithmetic_mean'>arithmetic mean</a>?</li>

<li>What activity?</li>

<li>What do you mean by month? <a href='http://en.wikipedia.org/wiki/Month#Months_in_various_calendars'>How many days are in it?</a></li>

<li>Over what time span is the average calculated? Does it <a href='http://en.wikipedia.org/wiki/Moving_average'>move</a>?</li>

<li>How are the numbers rounded? How is the <a href='http://en.wikipedia.org/wiki/Rounding#Tie-breaking'>tie broken</a>?</li>
</ul>

<p>Remember, the most hidden assumptions are those you yourself hold. As a tester, you need to challenge yourself and question everything.</p>
        </article>
      
    
      
        <article>
          <title>Ask better questions - Listen!</title>
          <p>Everything that follows is a result of what you see here.</p>

<p>Testing relies heavily on asking questions. Questions allow us to challenge assumptions, confirm what we already know and uncover the unknown. Coming up with the right questions and understanding what to do with the answers is a real skill. Consider yourself a detective or scientist, whichever you find more motivating.</p>

<p>Have you read/seen ‘i Robot’? In the story, Detective Spooner has to solve a murder. It starts with him questioning a hologram of the victim, Dr Lanning. The hologram is a simple program, it can only give limited responses to specific questions.</p>

<p>Detective Spooner collects pieces of information, assesses them and re-evaluates what he knows. He uses that to piece together the right questions, fueling the cycle until he uncovers the fundamental flaw that had made it into (mass) production.</p>

<p>He could have asked the hologram many mindless questions, but that may never have allowed him to reach the right one. Testing can be as simple as asking questions but they are futile if you’re not listening to the answers and constantly evaluating what you know.</p>

<p>Beware of robots.</p>
        </article>
      
    
      
        <article>
          <title>Mule Testing - proactively testing assumptions</title>
          <p>We were building a shiny new system that relied on data from a poorly understood legacy monster. Assumptions about this data were baked into our system. These unchallenged assumptions turned out to be wrong. Our shiny new system was no longer so shiny.</p>

<p>The wider the belief in the assumption, the more it’s en-grained in the business, the greater the need for it to be tested.</p>

<p>Why trust when you can know?</p>

<p>An example Mule test (<em>it&#8217;s blogging by example!</em>)</p>

<p>Start with the assumption: <em>&#8220;All products must have a category&#8221;</em> Find a way to challenge or validate it. In this case we would run a simple query against production data:</p>
<div class='highlight'><pre><code class='sql'><span class='k'>SELECT</span> <span class='o'>*</span> <span class='k'>FROM</span> <span class='n'>products</span> <span class='k'>WHERE</span> <span class='n'>category</span> <span class='k'>IS</span> <span class='k'>NULL</span>
</code></pre>
</div>
<p>If the assumption holds true then rest easy. If it turns out to be false, congratulations you have just prevented a major bug. Share it with the team and update your old assumption to include the new facts. In this example <em>&#8220;A product does not require a category&#8221;</em>.</p>

<p>Mule testing has limits. It only helps you test assumptions that you know about. If the magic combination of data that breaks your assumptions doesn’t yet exist, it won’t fail. It only works with access to the latest production data.</p>

<p>Why the name mule testing? Because some people got the wrong idea when we called it ass testing.</p>
        </article>
      
    
      
        <article>
          <title>Mule Specs - automated assumption testing</title>
          <p>In our last post we talked about <a href='http://cromulent-testing.com/2011/08/25/mule-testing-proactively-testing-assumptions.html'>mule testing</a>. Assumptions need automation because they’re the foundation our systems are built upon; they can change at anytime. Mule specs are a way to automate mule tests.</p>

<p>You can use any automated testing tool - the one your project already uses is probably fine. Unless it’s QTP. Below is the example from the <a href='http://cromulent-testing.com/2011/08/25/mule-testing-proactively-testing-assumptions.html'>last post</a> in RSpec using the sequel gem.</p>
<div class='highlight'><pre><code class='ruby'><span class='n'>describe</span> <span class='s1'>&#39;products&#39;</span> <span class='k'>do</span>
  <span class='n'>it</span> <span class='s1'>&#39;do not require a category&#39;</span> <span class='k'>do</span>
    <span class='n'>sql</span> <span class='o'>=</span> <span class='o'>&lt;&lt;-</span><span class='no'>SQL</span>
<span class='sh'>      SELECT count(1) as row_count</span>
<span class='sh'>      FROM product</span>
<span class='sh'>      WHERE category IS NULL</span>
<span class='no'>    SQL</span>

    <span class='n'>at_least_one_row_exists</span> <span class='n'>sql</span>
  <span class='k'>end</span>
<span class='k'>end</span>
</code></pre>
</div>
<p>We use two helper functions as we phrase our tests to expect either at least one result or no results.</p>
<div class='highlight'><pre><code class='ruby'><span class='k'>def</span> <span class='nf'>at_least_one_row_exists</span> <span class='n'>sql</span>
  <span class='no'>DB</span><span class='o'>[</span><span class='n'>sql</span><span class='o'>][</span><span class='ss'>:row_count</span><span class='o'>].</span><span class='n'>should</span> <span class='o'>!=</span> <span class='mi'>0</span>
<span class='k'>end</span>

<span class='k'>def</span> <span class='nf'>no_rows_exists</span> <span class='n'>sql</span>
  <span class='no'>DB</span><span class='o'>[</span><span class='n'>sql</span><span class='o'>][</span><span class='ss'>:row_count</span><span class='o'>].</span><span class='n'>should</span> <span class='o'>==</span> <span class='mi'>0</span>
<span class='k'>end</span>
</code></pre>
</div>
<h3 id='getting_production_data'>Getting production data</h3>

<p>Mule tests require prod data, the older and less realistic it is, the less certainty you have in your assumptions. Running Mule Specs on production data doesn’t mean running them on production, that’s a really bad idea. Copy the data elsewhere before execution. We arranged a sync from production every night and our Mule Specs run against it. So, when we arrive in the morning we know that as of yesterday, all our assumptions are still true.</p>

<p>Mule specs give us more than just a way of verifying assumptions. Written well, with good reporting, you produce verified documentation that’s updated every night when the mules run. Get the entire team involved. Ensure the analysts note their assumptions as they go and have the testers and developers implement them.</p>

<p>Follow your heart, run with the mules every night.</p>
        </article>
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  </articles>
</section>
  <section>
  <title>Automation</title>
  <articles>
    
      
    
      
    
      
    
      
    
      
    
      
        <article>
          <title>when should we be doing automated testing?</title>
          <p>Automated tests, that are written <strong>before</strong> the code; capture the intention of the code, inform design decisions, provide rapid feedback and let us know when we are done. All of this gets us thinking about testing and ensuring that our code can be automated.</p>

<p>One view of test automation is to write it <strong>after</strong> the system code has been written so the automation has to cope with less change. We&#8217;ve found this view doesn&#8217;t hold up in practice, firstly we spend a lot of time reverse engineering the code to automate it. Secondly, if the code is changing then this is when we need test automation the most to provide us with a safety net.</p>

<p>Automated tests that are written <strong>after</strong> the code do not directly inform the design nor do they provide rapid feedback. When writing automated tests in this way we need to ask ourselves; why are we taking this approach?</p>

<p>If we are doing it to provide test coverage or run in the CI build then we are coming to the party late. Without visibility into what automation already exists we could be duplicating test effort. If these tests will help us build a better product then they should be written <strong>before</strong> the code.</p>

<p>If we are using automation to do exploratory testing and we intend to throw the automation code away afterwards then we can write the tests <strong>after</strong>. Not all automation needs to be kept it just has to help us explore.</p>
        </article>
      
    
      
        <article>
          <title>Disposable Automation</title>
          <p>In our experience, testers have an unhealthy attachment to automated tests. We’re going to talk about times when throwaway automation is really helpful.</p>

<h3 id='record_and_playback'>Record and playback</h3>

<p>Sick and tired of clicking through page after page to find what you want to test? Record your path, run it, and test what actually matters. Record and playback is quick and easy. The code it creates will make your eyes bleed which doesn’t matter as long you dump it as soon as you’re done with it.</p>

<h3 id='exploratory_automation'>Exploratory Automation</h3>

<p>Sometimes you need to test things that can’t easily be done manually. We were exploring a bug lurking deep within a server and found ourselves manually crafting HTTP headers in telnet. We realised it’s a lot easier to do this in code. So we did. We found the bug and threw the automation away.</p>

<h3 id='permutations_and_combinations'>Permutations and Combinations</h3>

<p>There’s an adage that you can’t test everything. Sometimes, your tester senses tell you to cover a part of the system thoroughly. This can be done with a script that generates the various combinations. Run it over night and don’t leave your number.</p>

<p>Automation you decide to keep, you decide to maintain and “The things you own, end up owning you.” Tyler Durden</p>
        </article>
      
    
      
        <article>
          <title>the limits of automation</title>
          <p>Automation testing is frequently evangelised as the cure-all of software quality woes. However automated testing has limits on its effectiveness. Understanding these limits will keep us from trying to automate something that should never be.</p>

<h3 id='scoping_limitations'>Scoping Limitations</h3>

<p>In an automated test, deviations from the norm are not necessarily reported as failures. We can work around that by writing more tests, each of them focusing on one factor of the system.</p>

<p><strong>Practical Limitations</strong>: automation comes with a maintenance cost as the product evolves. This places practicality limits around what we automate. It’s not feasible to automate everything, as we must maintain everything. We need to be prudent about what tests we want to keep.</p>

<p><strong>Technological Limitations</strong>: some testing activities are just not possible to automate, like user experience testing. As soon as we move into the area where subjective qualities are being measured automation breaks down.</p>

<p><strong>Usefulness Limitations</strong>: automated tests do not provide equal value to the team. The high use post-deploy smoke test is more valuable than checking whether the user name field supports “Travis” as well as “Cornelius”. Just like we risk and value assess our manual testing effort we should be doing the same with automation.</p>

<h3 id='conflicting_limitations'>Conflicting Limitations</h3>

<p>The limitations we touched on they fall into two categories; those that force us to be smarter about the small set of tests we automate and those that drive us to want more tests. We can’t have both. How we deal with this is what makes a good tester.</p>
        </article>
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  </articles>
</section>
  <section>
  <title>Guidance</title>
  <div class="section-toc">
    <ul>
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
          <li>testing large datasets - an introduction</li>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    </ul>
  </div>
  <div class="articles">
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
        <div class="article">
          <h2>testing large datasets - an introduction</h2>
          <div class='highlight'><pre><code class='ruby'><span class='nb'>require</span> <span class='s1'>&#39;cromulent_testing&#39;</span>

<span class='n'>describe</span> <span class='s1'>&#39;automated testing,&#39;</span> <span class='k'>do</span>
  <span class='n'>describe</span> <span class='s1'>&#39;to involve the whole team&#39;</span> <span class='k'>do</span>
    <span class='n'>it</span> <span class='s1'>&#39;should make it easy for the team to contribute&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should include everyone in defining specifications&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should support the developers&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should be in the same language as the code&#39;</span>
  <span class='k'>end</span>

  <span class='n'>describe</span> <span class='s1'>&#39;to be an asset&#39;</span> <span class='k'>do</span>
    <span class='n'>it</span> <span class='s1'>&#39;should make it easier for the product to change&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should drive the domain model&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should generate human understandable documentation&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should cover the boring, repetative work&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should cover the high risk areas&#39;</span>
  <span class='k'>end</span>

  <span class='n'>describe</span> <span class='s1'>&#39;to be maintenable&#39;</span> <span class='k'>do</span>
    <span class='n'>it</span> <span class='s1'>&#39;should be organised in a way that makes sense&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should be easy to see why it failed&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should be discrete&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should be written as though it were production code&#39;</span>
  <span class='k'>end</span>

  <span class='n'>describe</span> <span class='s1'>&#39;to do it poorly&#39;</span> <span class='k'>do</span>
    <span class='n'>it</span> <span class='s1'>&#39;should be done after the manual testing&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should be done by a separate team&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should be done by people who don\&#39;t understand testing&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should be implemented by people who are not skilled in coding&#39;</span>
    <span class='n'>it</span> <span class='s1'>&#39;should summon a balrog!&#39;</span>
  <span class='k'>end</span>
<span class='k'>end</span>
</code></pre>
</div>
        </div>
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  </div>
</section>
  <section>
  <title>People</title>
  <div class="section-toc">
    <ul>
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
          <li>Do you know about test fatigue?</li>
        
      
        
          <li>Dealing with test fatigue</li>
        
      
        
      
        
      
        
      
        
      
        
      
    </ul>
  </div>
  <div class="articles">
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
        <div class="article">
          <h2>Do you know about test fatigue?</h2>
          <blockquote>
<p>Fatigue is a normal result of working, mental stress, overstimulation and understimulation, jet lag or active recreation, depression, and also boredom, disease and lack of sleep.[<a href='http://en.wikipedia.org/wiki/Fatigue_(medical)'>1</a>]</p>
</blockquote>

<p>We could rewrite the above quote to be:</p>

<p>Test fatigue is a normal result of testing, delivery pressures, thrashing, uninteresting work, disenfranchisement, mechanical work, bad practices and working overtime.</p>

<p>What’s wrong with that?</p>

<blockquote>
<p>&#8230;mental fatigue, in turn, can manifest itself both as somnolence (decreased wakefulness), or just as a general decrease of attention, not necessarily including sleepiness. Decreased attention is known as ego depletion and occurs when the limited &#8216;self regulatory capacity&#8217; is depleted. It may also be described as a more or less decreased level of consciousness. In any case, this can be dangerous when performing tasks that require constant concentration, such as driving a vehicle&#8230; [or testing][<a href='http://en.wikipedia.org/wiki/Fatigue_(medical)'>1</a>]</p>
</blockquote>

<p>This is a big topic, we have a lot more to say&#8230;stay tuned.</p>

<p>[1]: <a href='http://en.wikipedia.org/wiki/Fatigue_(medical'>http://en.wikipedia.org/wiki/Fatigue_(medical)</a></p>
        </div>
      
    
      
        <div class="article">
          <h2>Dealing with test fatigue</h2>
          <p>Here are the problems we raised in our <a href='http://cromulent-testing.com/2011/07/14/do-you-know-about-test-fatigue.html'>last post</a> and ways we deal with them.</p>

<p><strong>working overtime</strong> - You can’t test tired. If you’re going to be working overtime for several hours, have a break. Take time away from the project and go out for dinner, like a second lunch. Adjust the workplace to your style, watch <a href='http://www.youtube.com/watch?v=oHg5SJYRHA0'>YouTube</a> together and take frequent communal breaks.</p>

<p><strong>delivery pressures</strong> - The more pressure the team is under, the more likely they are to make mistakes and the more you need to test. <a href='http://bit.ly/lOw9RM'>DON’T PANIC.</a> The less time you have the more you need to get it right the first time.</p>

<p><strong>thrashing</strong> - Make a task list of what needs doing and divvy up the work. Stop people from interrupting (think: cone of silence) by politely explaining the urgency of what you’re working on. Remember, prioritisation! It’s normally better to finish some things than to partially complete lots of them.</p>

<p><strong>uninteresting work</strong> - Spice up boring work by trying it in a new way. Any technique will do, invent your own or try something from your <a href='http://cromulent-testing.com'>favourite testing blog</a>. You can make work fun.</p>

<p><strong>mechanical work</strong> - Automate it, computers love repetitive tasks. Even if you <a href='http://cromulent-testing.com/2011/07/05/disposable-automation.html'>dispose of it later</a>, you’re saving time. Delegate it to the development team, they love repetitive tasks.</p>

<p><strong>bad practices &amp; disenfranchisement</strong> - Why are you doing this to yourself? Good testers are a rare breed. Other companies want you, we want you. If you can’t fix it, leave.</p>
        </div>
      
    
      
    
      
    
      
    
      
    
      
    
  </div>
</section>
  <section>
  <title>Stories</title>
  <div class="section-toc">
    <ul>
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
          <li>Chicken Little</li>
        
      
        
      
    </ul>
  </div>
  <div class="articles">
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
        <div class="article">
          <h2>Chicken Little</h2>
          <p><em>Once upon a time there was a tiny chicken [tester] named Chicken Little. One day Chicken Little was scratching in the garden when an acorn fell on her head.</em> <em>&#8220;Oh,&#8221; cried Chicken Little, &#8220;The sky is falling! I must go tell the king [project manager].&#8221;</em></p>

<p>It’s important to remember that this is a tester who really cares, we need to harness their passion. A panicked approach causes stress and real problems get lost in the noise. The tester will lose credibility, become marginalised and burnout.</p>

<h2 id='harness_the_passion'>Harness the passion!</h2>

<p>We need to work closely with these testers who are emotionally invested and vulnerable to criticism. How they arrived at this behaviour is irrelevant. Two things we’ve found that help are to teach them prioritisation and to value quality over quantity.</p>

<h2 id='teach_them_to_prioritise'>Teach them to prioritise</h2>

<p>Ask them to rank bugs in the order they would like them fixed. If they struggle, begin by ranking one critical and one trivial bug. This forces them to understand some bugs are more important than others. Once they’re all ranked, discuss at which point we could release with the remaining bugs.</p>

<h2 id='value_them'>Value them</h2>

<p>Publicly acknowledge them for finding the good bugs. Let them see their good bugs being fixed. Recognise their less important bugs and use their prioritisation to explain why they won&#8217;t be fixed.</p>

<p>Teach them how to find the important bugs &#8230; coming soon</p>

<p><em>&#8230;and they all lived happily ever after.</em></p>
        </div>
      
    
      
    
  </div>
</section>
</body>
</doc>